{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:22.770791Z",
     "start_time": "2025-07-01T17:12:22.293122Z"
    }
   },
   "source": [
    "!pip install minsearch\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minsearch in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (0.0.3)\r\n",
      "Requirement already satisfied: pandas in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from minsearch) (2.3.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from minsearch) (1.7.0)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from pandas->minsearch) (2.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from pandas->minsearch) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from pandas->minsearch) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from pandas->minsearch) (2025.2)\r\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.16.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from scikit-learn->minsearch) (3.6.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:24.379484Z",
     "start_time": "2025-07-01T17:12:22.777368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import minsearch\n",
    "from openai import OpenAI\n"
   ],
   "id": "c06bc3b0790aa973",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:24.977497Z",
     "start_time": "2025-07-01T17:12:24.485066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ],
   "id": "932e0a2e1f0db10b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:26.067643Z",
     "start_time": "2025-07-01T17:12:26.065558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n"
   ],
   "id": "1ca3f15f5cdb315a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:27.528304Z",
     "start_time": "2025-07-01T17:12:27.525523Z"
    }
   },
   "cell_type": "code",
   "source": "q = 'the course already started, can i still enroll?'",
   "id": "43e7fced3fd738cf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:28.485738Z",
     "start_time": "2025-07-01T17:12:28.437162Z"
    }
   },
   "cell_type": "code",
   "source": "index.fit(documents)",
   "id": "48af78709d122f42",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x1271fbb90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:29.562736Z",
     "start_time": "2025-07-01T17:12:29.555145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "index.search(\n",
    "    query= q,\n",
    "    boost_dict = boost,\n",
    "    num_results=5\n",
    ")"
   ],
   "id": "ee455fd85145f1b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Yes, you can. You won‚Äôt be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers‚Äô Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course has already started. Can I still join it?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:31.525563Z",
     "start_time": "2025-07-01T17:12:31.523286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n"
   ],
   "id": "1d3c19a3076faa7f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:38.830238Z",
     "start_time": "2025-07-01T17:12:33.070543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=d_key,\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  extra_headers={\n",
    "    \"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "    \"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "  },\n",
    "  extra_body={},\n",
    "  model=\"deepseek/deepseek-r1-0528:free\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What is the meaning of life?\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "4724c4271a2ee3ca",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 20\u001B[39m\n\u001B[32m      1\u001B[39m client = OpenAI(\n\u001B[32m      2\u001B[39m   base_url=\u001B[33m\"\u001B[39m\u001B[33mhttps://openrouter.ai/api/v1\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      3\u001B[39m   api_key=d_key,\n\u001B[32m      4\u001B[39m )\n\u001B[32m      6\u001B[39m completion = client.chat.completions.create(\n\u001B[32m      7\u001B[39m   extra_headers={\n\u001B[32m      8\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mHTTP-Referer\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33m<YOUR_SITE_URL>\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;66;03m# Optional. Site URL for rankings on openrouter.ai.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     18\u001B[39m   ]\n\u001B[32m     19\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcompletion\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchoices\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m.message.content)\n",
      "\u001B[31mTypeError\u001B[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:38.832333Z",
     "start_time": "2025-06-27T17:08:59.441819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "completion = client.chat.completions.create(\n",
    "  extra_body={},\n",
    "  model=\"deepseek/deepseek-r1-0528:free\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": q\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "d2bd423b99f6c3ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Yes, it's often possible to enroll after a course has started, but you need to act quickly! Here's what to do and consider:**\n",
      "\n",
      "### ‚úÖ **Steps to Take:**\n",
      "1. **Contact the Instructor/Administrator Immediately:**\n",
      "   - **For academic courses:** Email the professor/instructor and the registrar or department admin. Ask:  \n",
      "     *\"Is late enrollment still possible? I'm willing to catch up on missed work.\"*\n",
      "   - **For online platforms (Coursera, Udemy, etc.):** Most allow self-paced enrollment‚Äîjust join and start (check the course page).\n",
      "   - **For bootcamps/workshops:** Email the organizer‚Äîflexibility varies.\n",
      "\n",
      "2. **Explain Your Situation Briefly:**\n",
      "   - Mention *why* you‚Äôre interested and confirm you‚Äôre committed to catching up.\n",
      "\n",
      "3. **Ask Key Questions:**\n",
      "   - \"What‚Äôs the latest enrollment date?\"\n",
      "   - \"Are there fees for late registration?\"\n",
      "   - \"Can I access materials from earlier sessions?\"\n",
      "   - \"Are assignments/exams flexible for late enrollees?\"\n",
      "\n",
      "### ‚ö†Ô∏è **Important Considerations:**\n",
      "- **Deadlines Matter:** Colleges often have strict \"add/drop\" deadlines (usually 1‚Äì2 weeks after start). **Act now‚Äîyou might have <48 hours.**\n",
      "- **Makeup Work:** You‚Äôll need to review missed content quickly. Ask for syllabi/recordings.\n",
      "- **Fees:** Late enrollment may incur extra charges (e.g., $50‚Äì$100).\n",
      "- **Instructor Approval:** Some courses require professor consent for late adds.\n",
      "\n",
      "### üìä **Likelihood of Approval:**\n",
      "| **Course Type**       | **Flexibility** | **Key Factor**                          |\n",
      "|------------------------|-----------------|------------------------------------------|\n",
      "| University/College     | Low-Moderate    | Registrar deadlines & professor approval |\n",
      "| Online MOOCs           | High            | Self-paced; join anytime                 |\n",
      "| Professional Workshops | Moderate        | Organizer discretion; class capacity    |\n",
      "| Bootcamps              | Low             | Cohort-based; strict start dates        |\n",
      "\n",
      "### üöÄ **Quick Tips:**\n",
      "- **Call** instead of emailing for faster response.\n",
      "- **Attend the next class** if permitted‚Äîshow initiative.\n",
      "- **Check the institution‚Äôs website** for late enrollment policies.\n",
      "\n",
      "**Bottom line:** **Don't wait‚Äîreach out TODAY.** Many programs allow late enrollment if space exists and you commit to catching up! üåü\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:12:38.832891Z",
     "start_time": "2025-06-27T17:09:25.037110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results\n"
   ],
   "id": "5250ab887519b36e",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:09:25.054399Z",
     "start_time": "2025-06-27T17:09:25.051581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ],
   "id": "d5bd32cd2e0c5763",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:09:25.062894Z",
     "start_time": "2025-06-27T17:09:25.060443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        extra_body={},\n",
    "        model=\"deepseek/deepseek-r1-0528:free\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ],
   "id": "80e582fe056242bd",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:09:25.070714Z",
     "start_time": "2025-06-27T17:09:25.069083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = 'how do I run kafka?'\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ],
   "id": "62258baf2e04117a",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:17:54.856967Z",
     "start_time": "2025-06-17T19:17:17.683081Z"
    }
   },
   "cell_type": "code",
   "source": "rag(query)\n",
   "id": "b2a93637f1d78ebe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based solely on the provided FAQ context, here's how to run Kafka components in specific scenarios:\\n\\n1.  **To run a Java Kafka producer/consumer/KStreams application from the terminal:**\\n    *   Navigate to the project directory.\\n    *   Run:\\n        ```bash\\n        java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n        ```\\n    *   (Replace `<jar_name>` with your actual JAR filename).\\n\\n2.  **To run Python Kafka scripts and avoid common issues:**\\n    *   **Resolve `Module ‚Äúkafka‚Äù not found`:** Create and activate a virtual environment:\\n        ```bash\\n        python -m venv env          # Create (run once)\\n        source env/bin/activate      # Activate (Linux/MacOS)\\n        # OR env\\\\Scripts\\\\activate   # Activate (Windows)\\n        pip install -r ../requirements.txt  # Install dependencies\\n        ```\\n        Run your Python files (e.g., `producer.py`) within this activated environment. Remember to activate it each time. Deactivate with `deactivate`.\\n    *   **Resolve `./build.sh: Permission denied`:** Navigate to the directory containing `build.sh` (e.g., `/docker/spark`) and run:\\n        ```bash\\n        chmod +x build.sh\\n        ```\\n    *   **Resolve `ModuleNotFoundError: No module named 'kafka.vendor.six.moves'`:** Install the alternative library:\\n        ```bash\\n        pip install kafka-python-ng\\n        ```\\n\\n3.  **Ensure dependencies for supporting libraries (like dlt for DuckDB):**\\n    ```bash\\n    pip install dlt[duckdb]\\n    pip install duckdb\\n    ```\\n\\n**Important Note:** The context consistently mentions the **requirement to have Docker images up and running** before executing Python Kafka scripts. **This is the core step for running the Kafka infrastructure itself (brokers, Zookeeper).** The methods above are for running *client applications* (producers, consumers, processing code) that connect to a Kafka cluster assumed to be running (likely via Docker as per the context).\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RAG with vector search",
   "id": "90e4a3daf1f316f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:13:11.688821Z",
     "start_time": "2025-07-01T17:13:11.225717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "qd_client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance\n"
   ],
   "id": "cfb581f173c6392f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduacapel/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:13:12.571059Z",
     "start_time": "2025-07-01T17:13:12.568518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EMBEDDING_DIMENSIONALITY =512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "collection_name = \"zoomcamp-faq\""
   ],
   "id": "90ac2f9fe9eb25bf",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ],
   "id": "1b60049907d3f70f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:23:18.735569Z",
     "start_time": "2025-06-27T17:23:18.716332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "points = []\n",
    "id = 0\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + \" \" + doc['text']\n",
    "    vector = models.Document(text = text, model = model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "    id += 1"
   ],
   "id": "3c3e1441bccb6a71",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:23:31.947914Z",
     "start_time": "2025-06-27T17:23:31.944625Z"
    }
   },
   "cell_type": "code",
   "source": "points[0]",
   "id": "856839a81277aa59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointStruct(id=0, vector=Document(text=\"Course - When will the course start? The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\", model='jinaai/jina-embeddings-v2-small-en', options=None), payload={'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:33:54.997719Z",
     "start_time": "2025-06-27T17:33:31.227600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qd_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ],
   "id": "11e003e4cdc4d2fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "query = 'I just discover the course, can I still join'",
   "id": "ed76bdd5fb3b354a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:42:15.301254Z",
     "start_time": "2025-06-27T17:42:15.235859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "course = 'data-engineering-zoomcamp'\n",
    "\n",
    "query_points = qd_client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=models.Document(  # Embed the query text locally\n",
    "        text=query,\n",
    "        model=model_handle\n",
    "    ),\n",
    "    query_filter=models.Filter(\n",
    "        must=[\n",
    "            models.FieldCondition(\n",
    "                key='course',\n",
    "                match=models.MatchValue(value=course)  # Fixed typo: \"MAtchValue\" ‚Üí \"MatchValue\"\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=5,  # Top 5 closest matches\n",
    "    with_payload=True  # Return metadata in results\n",
    ")\n"
   ],
   "id": "acd854181a52c699",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:38:27.499222Z",
     "start_time": "2025-06-27T17:38:27.496689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = [ ]\n",
    "for point in query_points.points:\n",
    "    results.append(point.payload)"
   ],
   "id": "537805014e5561e2",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:38:31.542014Z",
     "start_time": "2025-06-27T17:38:31.539393Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "bab92a342c36b528",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module ‚Äúkafka‚Äù not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n‚Äî--------------------------------------------------------------------------------------\",\n",
       "  'section': 'Workshop 2 - RisingWave',\n",
       "  'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T17:43:09.401024Z",
     "start_time": "2025-06-27T17:43:09.300514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\" # exact matching on string metadata fields\n",
    ")"
   ],
   "id": "c2e08528556970f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Homework",
   "id": "b0b0976570cbb5be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:29:54.855068Z",
     "start_time": "2025-07-01T17:29:46.239051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "model_name = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "text = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "embedding_vector = embeddings[0].numpy()\n",
    "print(embedding_vector.shape)\n",
    "print(embedding_vector.min())"
   ],
   "id": "3cba94831ed96bb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "-2.6467352\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:35:04.401303Z",
     "start_time": "2025-07-01T17:35:03.919894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "model_name = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return embedding[0].numpy()\n",
    "\n",
    "# Get embeddings\n",
    "q_vec = get_embedding(\"I just discovered the course. Can I join now?\")\n",
    "doc_vec = get_embedding(\"Can I still join the course after the start date?\")\n",
    "\n",
    "# Cosine similarity = dot product since vectors are normalized\n",
    "q_vec = q_vec / norm(q_vec)\n",
    "doc_vec = doc_vec / norm(doc_vec)\n",
    "\n",
    "cosine_similarity = np.dot(q_vec, doc_vec)\n",
    "print(cosine_similarity)"
   ],
   "id": "b0623f3b9e593729",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9017081\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:35:57.541726Z",
     "start_time": "2025-07-01T17:35:57.537940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ‚ù£Ô∏è\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]"
   ],
   "id": "9cf0eaa0942119b6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:37:19.054475Z",
     "start_time": "2025-07-01T17:37:18.522464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return embedding[0].numpy()\n",
    "\n",
    "documents = [\n",
    "    {\"text\": \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"},\n",
    "    {\"text\": \"Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\"},\n",
    "    {\"text\": \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\"},\n",
    "    {\"text\": \"You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.\"},\n",
    "    {\"text\": \"Star the repo! Share it with friends if you find it useful ‚ù£Ô∏è\\nCreate a PR if you see you can improve the text or the structure of the repository.\"}\n",
    "]\n",
    "\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "doc_embeddings = np.array([get_embedding(doc[\"text\"]) for doc in documents])\n",
    "query_embedding = get_embedding(query)\n",
    "\n",
    "doc_embeddings = doc_embeddings / np.linalg.norm(doc_embeddings, axis=1, keepdims=True)\n",
    "query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "\n",
    "similarities = doc_embeddings.dot(query_embedding)\n",
    "\n",
    "for idx, sim in enumerate(similarities):\n",
    "    print(f\"Document {idx} similarity: {sim:.3f}\")\n",
    "\n",
    "best_index = np.argmax(similarities)\n",
    "print(f\"\\n Most similar document index: {best_index}\")"
   ],
   "id": "da0a6bdeebd3144b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 similarity: 0.713\n",
      "Document 1 similarity: 0.732\n",
      "Document 2 similarity: 0.635\n",
      "Document 3 similarity: 0.705\n",
      "Document 4 similarity: 0.792\n",
      "\n",
      " Most similar document index: 4\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:38:40.372568Z",
     "start_time": "2025-07-01T17:38:40.310707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documents = [\n",
    "    {\n",
    "        \"question\": \"Course - Can I still join the course after the start date?\",\n",
    "        \"text\": \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Course - Can I follow the course after it finishes?\",\n",
    "        \"text\": \"Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Course - When will the course start?\",\n",
    "        \"text\": \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Course - What can I do before the course starts?\",\n",
    "        \"text\": \"You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can we contribute to the course?\",\n",
    "        \"text\": \"Star the repo! Share it with friends if you find it useful ‚ù£Ô∏è\\nCreate a PR if you see you can improve the text or the structure of the repository.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "query_vec = get_embedding(query)\n",
    "query_vec = query_vec / np.linalg.norm(query_vec)\n",
    "\n",
    "full_texts = [doc[\"question\"] + \" \" + doc[\"text\"] for doc in documents]\n",
    "doc_embeddings = np.array([get_embedding(text) for text in full_texts])\n",
    "doc_embeddings = doc_embeddings / np.linalg.norm(doc_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "similarities = doc_embeddings.dot(query_vec)\n",
    "\n",
    "for i, sim in enumerate(similarities):\n",
    "    print(f\"Document {i} similarity: {sim:.3f}\")\n",
    "\n",
    "best_index = np.argmax(similarities)\n",
    "print(f\"\\n Most similar document index: {best_index}\")"
   ],
   "id": "e78840e852996ee3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 similarity: 0.673\n",
      "Document 1 similarity: 0.720\n",
      "Document 2 similarity: 0.649\n",
      "Document 3 similarity: 0.741\n",
      "Document 4 similarity: 0.740\n",
      "\n",
      " Most similar document index: 3\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:42:00.130142Z",
     "start_time": "2025-07-01T17:42:00.126610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# q5\n",
    "import json\n",
    "from fastembed import TextEmbedding\n",
    "TextEmbedding.list_supported_models()\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] < 500:\n",
    "        print(json.dumps(model, indent=2))"
   ],
   "id": "b6d27cfb7c9f8632",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-small-en\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/bge-small-en\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.13,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"BAAI/bge-small-en-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"qdrant/bge-small-en-v1.5-onnx-q\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.067,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"snowflake/snowflake-arctic-embed-xs\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"snowflake/snowflake-arctic-embed-xs\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"snowflake/snowflake-arctic-embed-s\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"snowflake/snowflake-arctic-embed-s\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.13,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"qdrant/all-MiniLM-L6-v2-onnx\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.22,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 384,\n",
      "  \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:54:57.727117Z",
     "start_time": "2025-07-01T17:54:54.163255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "documents_raw = requests.get(docs_url).json()\n",
    "\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    if course['course'] != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course['course']\n",
    "        documents.append(doc)\n",
    "\n",
    "model_handle = \"BAAI/bge-small-en\"\n",
    "EMBEDDING_DIM = 384\n",
    "\n",
    "collection_name = \"ml-zoomcamp-faq\"\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIM,\n",
    "        distance=models.Distance.COSINE,\n",
    "    )\n",
    ")\n",
    "\n",
    "points = []\n",
    "for i, doc in enumerate(documents):\n",
    "    full_text = doc['question'] + \" \" + doc['text']\n",
    "    vector = models.Document(text = text, model = model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "results = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query,\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "print(f\"Top similarity score: {results[0].score:.4f}\")"
   ],
   "id": "5e5350b837c6e6c4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/95/00r3y4ys0cxgk7xbsyl1smv00000gn/T/ipykernel_69953/1686003113.py:23: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n",
      "Fetching 5 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  2.44it/s]\n",
      "/var/folders/95/00r3y4ys0cxgk7xbsyl1smv00000gn/T/ipykernel_69953/1686003113.py:53: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for SearchRequest\nvector.list[float]\n  Input should be a valid list [type=list_type, input_value='I just discovered the course. Can I join now?', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type\nvector.NamedVector\n  Input should be a valid dictionary or instance of NamedVector [type=model_type, input_value='I just discovered the course. Can I join now?', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\nvector.NamedSparseVector\n  Input should be a valid dictionary or instance of NamedSparseVector [type=model_type, input_value='I just discovered the course. Can I join now?', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValidationError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 53\u001B[39m\n\u001B[32m     50\u001B[39m query = \u001B[33m\"\u001B[39m\u001B[33mI just discovered the course. Can I join now?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     52\u001B[39m \u001B[38;5;66;03m# Run similarity search\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m results = \u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquery_vector\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     56\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlimit\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     57\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwith_payload\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[32m     58\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;66;03m# Show top score\u001B[39;00m\n\u001B[32m     61\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTop similarity score: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults[\u001B[32m0\u001B[39m].score\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages/qdrant_client/qdrant_client.py:376\u001B[39m, in \u001B[36mQdrantClient.search\u001B[39m\u001B[34m(self, collection_name, query_vector, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, append_payload, consistency, shard_key_selector, timeout, **kwargs)\u001B[39m\n\u001B[32m    369\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) == \u001B[32m0\u001B[39m, \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnknown arguments: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(kwargs.keys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    370\u001B[39m warnings.warn(\n\u001B[32m    371\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m`search` method is deprecated and will be removed in the future.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    372\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m Use `query_points` instead.\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    373\u001B[39m     \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m,\n\u001B[32m    374\u001B[39m     stacklevel=\u001B[32m2\u001B[39m,\n\u001B[32m    375\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m376\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    377\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    378\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquery_vector\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_vector\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquery_filter\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_filter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m    \u001B[49m\u001B[43msearch_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43msearch_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlimit\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m    \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m=\u001B[49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwith_payload\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwith_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    384\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwith_vectors\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwith_vectors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    385\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscore_threshold\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscore_threshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m    \u001B[49m\u001B[43mappend_payload\u001B[49m\u001B[43m=\u001B[49m\u001B[43mappend_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconsistency\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconsistency\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m    \u001B[49m\u001B[43mshard_key_selector\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshard_key_selector\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages/qdrant_client/qdrant_remote.py:527\u001B[39m, in \u001B[36mQdrantRemote.search\u001B[39m\u001B[34m(self, collection_name, query_vector, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, append_payload, consistency, shard_key_selector, timeout, **kwargs)\u001B[39m\n\u001B[32m    520\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(with_payload, grpc.WithPayloadSelector):\n\u001B[32m    521\u001B[39m     with_payload = GrpcToRest.convert_with_payload_selector(with_payload)\n\u001B[32m    523\u001B[39m search_result = \u001B[38;5;28mself\u001B[39m.http.search_api.search_points(\n\u001B[32m    524\u001B[39m     collection_name=collection_name,\n\u001B[32m    525\u001B[39m     consistency=consistency,\n\u001B[32m    526\u001B[39m     timeout=timeout,\n\u001B[32m--> \u001B[39m\u001B[32m527\u001B[39m     search_request=\u001B[43mmodels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSearchRequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    528\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvector\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_vector\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    529\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m=\u001B[49m\u001B[43mquery_filter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    530\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlimit\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    531\u001B[39m \u001B[43m        \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m=\u001B[49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    532\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m=\u001B[49m\u001B[43msearch_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    533\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwith_vector\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwith_vectors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    534\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwith_payload\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwith_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    535\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscore_threshold\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscore_threshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    536\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshard_key\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshard_key_selector\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    537\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    538\u001B[39m )\n\u001B[32m    539\u001B[39m result: Optional[\u001B[38;5;28mlist\u001B[39m[types.ScoredPoint]] = search_result.result\n\u001B[32m    540\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mSearch returned None\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/LLM-Zoomcamp/.venv/lib/python3.12/site-packages/pydantic/main.py:253\u001B[39m, in \u001B[36mBaseModel.__init__\u001B[39m\u001B[34m(self, **data)\u001B[39m\n\u001B[32m    251\u001B[39m \u001B[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001B[39;00m\n\u001B[32m    252\u001B[39m __tracebackhide__ = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m253\u001B[39m validated_self = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__pydantic_validator__\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalidate_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mself_instance\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m validated_self:\n\u001B[32m    255\u001B[39m     warnings.warn(\n\u001B[32m    256\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mA custom validator is returning a value other than `self`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m'\u001B[39m\n\u001B[32m    257\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mReturning anything other than `self` from a top level model validator isn\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt supported when validating via `__init__`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    258\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m    259\u001B[39m         stacklevel=\u001B[32m2\u001B[39m,\n\u001B[32m    260\u001B[39m     )\n",
      "\u001B[31mValidationError\u001B[39m: 3 validation errors for SearchRequest\nvector.list[float]\n  Input should be a valid list [type=list_type, input_value='I just discovered the course. Can I join now?', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type\nvector.NamedVector\n  Input should be a valid dictionary or instance of NamedVector [type=model_type, input_value='I just discovered the course. Can I join now?', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\nvector.NamedSparseVector\n  Input should be a valid dictionary or instance of NamedSparseVector [type=model_type, input_value='I just discovered the course. Can I join now?', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T17:56:35.176453Z",
     "start_time": "2025-07-01T17:56:30.221988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fastembed.embedding import DefaultEmbedding\n",
    "embedding_model = DefaultEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "EMBEDDING_DIM = 384\n",
    "collection_name = \"ml-zoomcamp-faq\"\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIM,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "points = []\n",
    "for i, doc in enumerate(documents):\n",
    "    full_text = doc['question'] + \" \" + doc['text']\n",
    "    # Embed the full_text (returns a generator, get first vector)\n",
    "    vector = next(embedding_model.embed([full_text]))\n",
    "\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector.tolist(),  # convert numpy array to list if needed\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "client.upsert(collection_name=collection_name, points=points)\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_vector = next(embedding_model.embed([query]))\n",
    "results = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_vector.tolist(),\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "print(f\"Top similarity score: {results[0].score:.4f}\")"
   ],
   "id": "a5136077d4d55fac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-07-01 18:56:30.224\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36mfastembed.embedding\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m7\u001B[0m - \u001B[33m\u001B[1mDefaultEmbedding, FlagEmbedding, JinaEmbedding are deprecated.Use from fastembed import TextEmbedding instead.\u001B[0m\n",
      "/var/folders/95/00r3y4ys0cxgk7xbsyl1smv00000gn/T/ipykernel_69953/695693142.py:10: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similarity score: 0.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/95/00r3y4ys0cxgk7xbsyl1smv00000gn/T/ipykernel_69953/695693142.py:42: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
